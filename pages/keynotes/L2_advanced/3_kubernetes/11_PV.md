---
title: 存储卷
keywords: keynotes, advanced, kubernetes, CKA, VOLUMES
permalink: keynotes_L2_advanced_3_kubernetes_10_PV.html
sidebar: keynotes_L2_advanced_sidebar
typora-copy-images-to: ./pics/11_PV
typora-root-url: ../../../../../cloudnative365.github.io
---

## 课程目标
- 了解和创建PV（Persistent volumes）
- 配置pvc（persistent volumes claims）
- 管理卷的访问模式
- 部署一个带存持久存储的应用
- 动态提供存储

## 1. 简介
传统环境中，存储空间会随着容器的终止而终止，没办法提供持久存储。由于容器被认为是瞬时的，这可能导致数据丢失或复杂的外部存储选项。Kubernetes**卷**共享Pod生存期，而不是其中的容器。如果容器终止，数据将继续对新容器可用。

卷是一个目录，可以是预先写好内容的，可供Pod中的容器使用。目录的创建、数据的后端存储和内容取决于卷类型。在v1.13，共有27种不同的卷类型，从rbd到访问Ceph、NFS，再到来自像Google的gcePersistentDisk这样的云提供商的动态卷。每个都有特定的配置选项和依赖项。

容器存储接口（CSI）的采用为容器编排的行业标准接口，他的目标是允许通过接口访问任意存储系统。目前，卷插件“in tree”，这意味着它们是用核心Kubernetes二进制文件编译和构建的。“不在树中的”对象将允许存储供应商开发单个驱动程序，并允许插件被容器化。这将取代现有插件，他是需要提升主机节点访问权限的，这是一个很大的安全问题。

如果希望存储生命周期与Pod不同，可以使用持久卷。这些允许Pod使用pvc来声明空的或预填充的卷，然后生命周期比Pod还长。也就是说在pod终止之后可以继续存在。然后，卷内的数据可以被另一个Pod使用，或者作为检索数据的手段。

已经有两个API对象来向Pod提供数据。加密数据可以使用secret传递，非加密数据可以使用ConfigMap传递。它们可以用来传递重要的数据，比如SSH密钥、密码，甚至是配置文件，比如**/etc/hosts**。

## 2. 卷组

Pod的spec可以声明一个或多个卷及其可用位置。每个都需要一个name、一个type和一个mountpoint。一个Pod中的多个容器可以使用相同的卷，这可以作为一种容器到容器通信的方法。一个卷可以提供给多个pod，每个pod都有一个访问模式。如果没有并发性检查，这意味着数据可能会损坏，除非我们使用外部锁定。

![njibb9wicexq-KubernetesPodVolumes](/pages/keynotes/L2_advanced/3_kubernetes/pics/11_PV/njibb9wicexq-KubernetesPodVolumes.png)

### 2.1. Kubernetes Pod Volumes

特定的访问模式是Pod请求的一部分。作为请求，用户可以被授予更多但不是更少的访问权限，尽管首先尝试直接匹配。群集将具有相同模式的卷分组在一起，然后按大小从最小到最大对卷进行排序。在足够大的卷匹配之前，将针对该访问模式组中的每个卷检查声明。三种访问模式是：

- ReadWriteOnce，允许单个节点读写，RWO

- ReadOnlyMany，允许多个节点只读，RO

- read write many，允许多个节点读写，RW

因此，同一节点上的两个pod可以写入ReadWriteOnce，但另一节点上的第三个pod会因为FailedAttachVolume错误而无法就绪。

当请求卷时，本地kubelet使用**kubelet_pods.go**脚本映射裸设备，决定并确保容器的mountpoint，然后在主机节点文件系统上创建符号链接，将存储与容器关联。API服务器向**StorageClass**插件发出存储请求，但对后端存储的请求具体取决于正在使用的插件。

如果没有对特定的**StorageClass**发出请求，则使用的唯一参数是mode和size。卷可以来自任何可用的存储类型，并且没有配置来确定将使用哪种可用的存储类型。

### 2.2. Volume Spec

最常用的存储类型之一是**emptyDir**。kubelet将在容器中创建目录，但不mount任何存储。创建的任何数据都将写入共享容器空间。因此，它不会是持久性存储。当Pod被销毁时，目录将与容器一起被删除。

``` yaml
apiVersion: v1
kind: Pod
metadata:
  name: fordpinto 
  namespace: default
spec:
  containers:
  - image: simpleapp 
    name: gastank 
    command:
    - sleep
    - "3600"
    volumeMounts:
    - mountPath: /scratch
      name: scratch-volume
  volumes:
  - name: scratch-volume
    emptyDir: {}
```

上面的YAML文件将创建一个Pod，其中包含一个名为**scratch volume**的卷，该卷将在容器内创建**/scratch**目录。

### 2.3. 存储卷类型

有几种类型可用于定义卷，每种类型都有其优缺点。有些是本地的，许多是利用基于网络的资源。

在GCE或AWS中，您可以使用类型为**GCEpersistentDisk**或**awsElasticBlockStore**的卷，需要允许在已设置帐户和权限的情况下在Pod中装载GCE和EBS磁盘。

**emptyDir**和**hostPath**卷易于使用。如前所述，**emptyDir**是一个空目录，在Pod终止时被删除，但在容器重新启动时被重新创建。**hostPath**卷从主机节点文件系统装载资源。资源可以是目录、文件套接字、字符或块设备。这些资源必须已经存在于要使用的主机上。有两种类型，**directoryocreate**和**FileOrCreate**，它们在主机上创建资源，如果它们还不存在，则使用它们。

NFS（网络文件系统）和iSCSI(Internet Small Computer System Interface)是多个阅读器场景的常用选择。

块存储或cepfs和GlusterFS的rbd（如果在Kubernetes集群中可用）对于多个writer需求来说是一个不错的选择。

除了我们刚才提到的卷类型之外，还有很多其他的可能，还有更多的可能：**azureDisk**、**azureFile**、**csi**、**downwardAPI**、**fc**（光纤通道）、**flocker**、**gitRepo**、**local**、**projected**、**portworxVolume**、**quobyte**、**scaleIO**、**secret**、**storageos**、**vsphereVolume**、**persistenvolumeclaim**，**CSIPersistentVolumeSource** 等。

CSI允许更多的灵活的和解耦的插件，而无需编辑核心Kubernetes代码。它是作为将来公开任意插件的标准而开发的。

### 2.4. 共享卷组

下面的YAML文件创建了一个pod，**exampleA**，他包含了两个容器，两个容器共享一个存储卷。

``` yaml
....
   containers:
   - name: alphacont
     image: busybox
     volumeMounts:
     - mountPath: /alphadir
       name: sharevol
   - name: betacont
     image: busybox
     volumeMounts:
     - mountPath: /betadir
       name: sharevol
   volumes:
   - name: sharevol
     emptyDir: {}  
```

``` bash
$ kubectl exec -ti exampleA -c betacont -- touch /betadir/foobar
$ kubectl exec -ti exampleA -c alphacont -- ls -l /alphadir

total 0
-rw-r--r-- 1 root root 0 Nov 19 16:26 foobar
```

我们可以很容易地使用**emptyDir**或**hostPath**，因为这些类型不需要任何额外的设置，并且可以在Kubernetes集群中工作。

注意，一个容器（**betacont**）写入，另一个容器（**alphacont**）可以立即访问数据。没有什么可以阻止容器覆盖另一个容器的数据。锁定或版本控制等注意的地方是容器化应用程序的重要一环，以避免损坏。



## 3. Persistent Volume

下面这个例子是PV使用hostPath类型的一个示例

```yaml
kind: PersistentVolume
apiVersion: v1
metadata:
    name: 10Gpv01
    labels: 
        type: local 
spec:
    capacity: 
        storage: 10Gi
    accessModes:
        - ReadWriteOnce
    hostPath:
        path: "/somepath/data01"
```

每一种类型都有他自己独特的配置。比如，一个已经创建了Ceph或者GCE持久存储的盘就不需要配置Ceph和GCE了，而是需要从provider去声明自己使用哪种存储。

PV不属于任何的namespace，但是pvc是属于某一个namespace的。从1.13版本中的beta特性开始允许配置静态的裸盘。目前已经支持FC，AWS EBS，Azure Disk和 RBD等多种插件。

使用本地的附加存储目前已经毕业成为一个稳定版。这个特性经常被用来做分布式文件系统和数据库



## 4. Persistent Volume Claim

当我们的集群中有pv的时候，我们就可以在清单文件中声明使用了。我们可以在使用pod的时候去定义一个声明。在Pod中，定义卷组的时候使用**persistentVolumeClaim**

```yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
    name: myclaim
spec:
    accessModes:
        - ReadWriteOnce
    resources:
        requests:
                storage: 8GI
```

In the Pod:

```yaml
spec:
    containers:
....
    volumes:
        - name: test-volume
          persistentVolumeClaim:
                claimName: myclaim
```

Pod中复杂一点的配置就像下面这个样子

```yaml
volumeMounts:
      - name: Cephpd
        mountPath: /data/rbd
  volumes:
    - name: rbdpd
      rbd:
        monitors:
        - '10.19.14.22:6789'
        - '10.19.14.23:6789'
        - '10.19.14.24:6789'
        pool: k8s
        image: client
        fsType: ext4
        readOnly: true
        user: admin
        keyring: /etc/ceph/keyring
        imageformat: "2"
        imagefeatures: "layering"
```



## 5. 动态配置Dynamic Provisioning

在使用卷组的时候，我们使用pv先定义好一类存储，然后抽象的使用存储的provider去声明使用很方便，但是集群的管理员仍然需要预先定义这些卷。从kubernetes1.4版本之后，Dynamic Provisioning允许集群从外部申请预先配置好的资源。API调用通过插件可以支持很多类型的动态存储。

 **StorageClass**这种API资源就能够让管理员去定义一个由特殊类型定义的一个pv。

**StorageClass**创建之后，用户可以申请一个claim，API server会自动的配置符合要求的存储。资源还会被provide重新claim。我们通常会选择AWS或者GCE作为动态的存储，当然我们也可以选择其他的类型，比如Ceph或者iSCSI。通常来说，默认的类型是使用annotation来声明的。

下面是一个使用GCE的例子

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast      # Could be any name
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-ssd 
```
