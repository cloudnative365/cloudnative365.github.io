<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>最困难的方式安装k8s集群 | cloudnative365.github.io</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="最困难的方式安装k8s集群" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/keynotes_L3_senior_2_kubernetes_2_hardest_way.html" />
<meta property="og:url" content="http://localhost:4000/keynotes_L3_senior_2_kubernetes_2_hardest_way.html" />
<meta property="og:site_name" content="cloudnative365.github.io" />
<script type="application/ld+json">
{"headline":"最困难的方式安装k8s集群","url":"http://localhost:4000/keynotes_L3_senior_2_kubernetes_2_hardest_way.html","@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=481468f1311b237dbb8ec4fec8c1099b04cbcc76">
  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="http://localhost:4000/">cloudnative365.github.io</a></h1>
      

      <h2 id="1-简介">1. 简介</h2>

<p>我们都知道在kubernetes的业界有一个标准，叫the easy way of kubernetes和the hard way of kubernetes。他们分别是指kops安装kubernetes和二进制方式安装kubernetes。二进制方式安装的文档在<a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">github</a>上。在写这篇文档的时候，我参考了一下git上文档，他已经更新到了1.15这个版本，而我目前在使用的是1.18.3版本。所以我打算在增加点难度。</p>

<h2 id="2-加大难度">2. 加大难度</h2>

<p>在看git的文档的时候，我发现还可以加大难度。</p>

<ul>
  <li>整篇文章只用了一组CA签署了一组证书，但是如果使用kubeadm安装的时候是两组CA（etcd一组ca和kubenetes的control-panel一组ca）创建了八组证书(etcd三组和kubernetes五组)</li>
  <li>整篇文章没有考虑权限和硬盘规划问题，我觉得还可以在权限和硬盘规划上再增加难度，做成生成级别的系统</li>
</ul>

<h2 id="3-架构图">3. 架构图</h2>

<p><img src="/pages/keynotes/L3_senior/2_kubernetes/pics/2_hardest_way/kubeadm-ha-topology-external-etcd.svg" alt="External etcd topology" />来自<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/">网站</a></p>

<h2 id="4-软硬件清单">4. 软硬件清单</h2>

<h3 id="41-硬件环境">4.1. 硬件环境</h3>

<p>平台环境：AWS</p>

<p>机器列表</p>

<table>
  <thead>
    <tr>
      <th>hostname</th>
      <th>型号</th>
      <th>功能</th>
      <th>子网</th>
      <th>IP地址</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>master1</td>
      <td>t3.medium</td>
      <td>control-plane</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>master2</td>
      <td>t3.medium</td>
      <td>control-plane</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>master3</td>
      <td>t3.medium</td>
      <td>control-plane</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>master1</td>
      <td>t3.medium</td>
      <td>etcd</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>master2</td>
      <td>t3.medium</td>
      <td>etcd</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>master3</td>
      <td>t3.medium</td>
      <td>etcd</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>jumpserver</td>
      <td>t3.medium</td>
      <td>load balancer for internal traffic</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>jumpserver</td>
      <td>t3.medium</td>
      <td>load balancer for external traffic</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>jumpserver</td>
      <td>t3.medium</td>
      <td>jumpserver for managing the cluster</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>node1</td>
      <td>t3.medium</td>
      <td>worker</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>node2</td>
      <td>t3.medium</td>
      <td>worker</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="42-软件环境">4.2. 软件环境</h3>

<p>操作系统：ubuntu：16.04.6</p>

<p>docker：19.03.4</p>

<p>containerd：1.2.10</p>

<p>kubernetes：1.18.3</p>

<p>CoreDNS：</p>

<p>Calico：</p>

<h2 id="5-准备环境">5. 准备环境</h2>

<h3 id="51-在公有云环境中创建硬件清单中的机器">5.1. 在公有云环境中创建硬件清单中的机器</h3>

<h3 id="52-配置lb机器为我们的跳板机配置他免密登录其他的机器">5.2. 配置LB机器为我们的跳板机，配置他免密登录其他的机器</h3>

<h2 id="6-安装工具">6. 安装工具</h2>

<h3 id="61-下载相应的工具">6.1. 下载相应的工具</h3>

<h3 id="62-下载相应的包">6.2. 下载相应的包</h3>

<h2 id="补充使用kubeadm完成下面的7到9步">补充：使用kubeadm完成下面的7到9步</h2>

<p>参考<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/">官方文档</a></p>

<h2 id="7-安装etcd">7. 安装etcd</h2>

<h2 id="8-创建证书etcd的三组">8. 创建证书（etcd的三组）</h2>

<h2 id="9-配置带ssl认证的etcd">9. 配置带ssl认证的etcd</h2>

<h2 id="10-安装负载均衡">10. 安装负载均衡</h2>

<h2 id="补充使用kubeadm完成下面的11到14步">补充：使用kubeadm完成下面的11到14步</h2>

<p>参考：<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">官方文档</a></p>

<h2 id="11-创建kubernetes证书kubernetes的五组">11. 创建kubernetes证书（kubernetes的五组）</h2>

<h2 id="12-安装api-server">12. 安装api-server</h2>

<h2 id="13-安装api-scheduler">13. 安装api-scheduler</h2>

<h2 id="14-安装api-controller-manager">14. 安装api-controller-manager</h2>

<h2 id="15-安装kubelet">15. 安装kubelet</h2>

<h2 id="16-安装coredns">16. 安装CoreDNS</h2>

<h2 id="17-安装calico">17. 安装Calico</h2>

<h2 id="18-安装ingressdashboardhelmprometheus">18. 安装Ingress，dashboard，helm，prometheus</h2>

<p>所有的key</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@ip-10-0-1-80:/etc/kubernetes/pki# find <span class="nb">.</span>
<span class="nb">.</span>
./ca.crt
./apiserver-kubelet-client.crt
./ca.key
./front-proxy-client.key
./sa.pub
./sa.key
./front-proxy-ca.crt
./front-proxy-ca.key
./apiserver.key
./apiserver.crt
./apiserver-etcd-client.crt
./etcd
./etcd/ca.crt
./etcd/server.crt
./etcd/healthcheck-client.crt
./etcd/ca.key
./etcd/peer.crt
./etcd/server.key
./etcd/peer.key
./etcd/healthcheck-client.key
./front-proxy-client.crt
./apiserver-kubelet-client.key
./apiserver-etcd-client.key
</code></pre></div></div>

<p>etcd</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@ip-10-0-1-80:/etc/kubernetes/manifests# <span class="nb">cat </span>etcd.yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/etcd.advertise-client-urls: https://10.0.1.80:2379
  creationTimestamp: null
  labels:
    component: etcd
    tier: control-plane
  name: etcd
  namespace: kube-system
spec:
  containers:
  - <span class="nb">command</span>:
    - etcd
    - <span class="nt">--advertise-client-urls</span><span class="o">=</span>https://10.0.1.80:2379
    - <span class="nt">--cert-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt
    - <span class="nt">--client-cert-auth</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--data-dir</span><span class="o">=</span>/var/lib/etcd
    - <span class="nt">--initial-advertise-peer-urls</span><span class="o">=</span>https://10.0.1.80:2380
    - <span class="nt">--initial-cluster</span><span class="o">=</span>ip-10-0-1-80<span class="o">=</span>https://10.0.1.80:2380
    - <span class="nt">--key-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/server.key
    - <span class="nt">--listen-client-urls</span><span class="o">=</span>https://127.0.0.1:2379,https://10.0.1.80:2379
    - <span class="nt">--listen-metrics-urls</span><span class="o">=</span>http://127.0.0.1:2381
    - <span class="nt">--listen-peer-urls</span><span class="o">=</span>https://10.0.1.80:2380
    - <span class="nt">--name</span><span class="o">=</span>ip-10-0-1-80
    - <span class="nt">--peer-cert-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/peer.crt
    - <span class="nt">--peer-client-cert-auth</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--peer-key-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/peer.key
    - <span class="nt">--peer-trusted-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt
    - <span class="nt">--snapshot-count</span><span class="o">=</span>10000
    - <span class="nt">--trusted-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt
    image: k8s.gcr.io/etcd:3.4.3-0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /health
        port: 2381
        scheme: HTTP
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: etcd
    resources: <span class="o">{}</span>
    volumeMounts:
    - mountPath: /var/lib/etcd
      name: etcd-data
    - mountPath: /etc/kubernetes/pki/etcd
      name: etcd-certs
  hostNetwork: <span class="nb">true
  </span>priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki/etcd
      <span class="nb">type</span>: DirectoryOrCreate
    name: etcd-certs
  - hostPath:
      path: /var/lib/etcd
      <span class="nb">type</span>: DirectoryOrCreate
    name: etcd-data
status: <span class="o">{}</span>
</code></pre></div></div>

<p>api-server</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.0.1.80:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - <span class="nb">command</span>:
    - kube-apiserver
    - <span class="nt">--advertise-address</span><span class="o">=</span>10.0.1.80
    - <span class="nt">--allow-privileged</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--authorization-mode</span><span class="o">=</span>Node,RBAC
    - <span class="nt">--client-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/ca.crt
    - <span class="nt">--enable-admission-plugins</span><span class="o">=</span>NodeRestriction
    - <span class="nt">--enable-bootstrap-token-auth</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--etcd-cafile</span><span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt
    - <span class="nt">--etcd-certfile</span><span class="o">=</span>/etc/kubernetes/pki/apiserver-etcd-client.crt
    - <span class="nt">--etcd-keyfile</span><span class="o">=</span>/etc/kubernetes/pki/apiserver-etcd-client.key
    - <span class="nt">--etcd-servers</span><span class="o">=</span>https://127.0.0.1:2379
    - <span class="nt">--insecure-port</span><span class="o">=</span>0
    - <span class="nt">--kubelet-client-certificate</span><span class="o">=</span>/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - <span class="nt">--kubelet-client-key</span><span class="o">=</span>/etc/kubernetes/pki/apiserver-kubelet-client.key
    - <span class="nt">--kubelet-preferred-address-types</span><span class="o">=</span>InternalIP,ExternalIP,Hostname
    - <span class="nt">--proxy-client-cert-file</span><span class="o">=</span>/etc/kubernetes/pki/front-proxy-client.crt
    - <span class="nt">--proxy-client-key-file</span><span class="o">=</span>/etc/kubernetes/pki/front-proxy-client.key
    - <span class="nt">--requestheader-allowed-names</span><span class="o">=</span>front-proxy-client
    - <span class="nt">--requestheader-client-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/front-proxy-ca.crt
    - <span class="nt">--requestheader-extra-headers-prefix</span><span class="o">=</span>X-Remote-Extra-
    - <span class="nt">--requestheader-group-headers</span><span class="o">=</span>X-Remote-Group
    - <span class="nt">--requestheader-username-headers</span><span class="o">=</span>X-Remote-User
    - <span class="nt">--secure-port</span><span class="o">=</span>6443
    - <span class="nt">--service-account-key-file</span><span class="o">=</span>/etc/kubernetes/pki/sa.pub
    - <span class="nt">--service-cluster-ip-range</span><span class="o">=</span>10.96.0.0/12
    - <span class="nt">--tls-cert-file</span><span class="o">=</span>/etc/kubernetes/pki/apiserver.crt
    - <span class="nt">--tls-private-key-file</span><span class="o">=</span>/etc/kubernetes/pki/apiserver.key
    image: k8s.gcr.io/kube-apiserver:v1.18.3
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 10.0.1.80
        path: /healthz
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-apiserver
    resources:
      requests:
        cpu: 250m
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: <span class="nb">true</span>
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: <span class="nb">true</span>
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: <span class="nb">true</span>
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: <span class="nb">true</span>
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: <span class="nb">true
  </span>hostNetwork: <span class="nb">true
  </span>priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      <span class="nb">type</span>: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /etc/kubernetes/pki
      <span class="nb">type</span>: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /usr/local/share/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: usr-share-ca-certificates
status: <span class="o">{}</span>
</code></pre></div></div>

<p>controller</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - <span class="nb">command</span>:
    - kube-controller-manager
    - <span class="nt">--allocate-node-cidrs</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--authentication-kubeconfig</span><span class="o">=</span>/etc/kubernetes/controller-manager.conf
    - <span class="nt">--authorization-kubeconfig</span><span class="o">=</span>/etc/kubernetes/controller-manager.conf
    - <span class="nt">--bind-address</span><span class="o">=</span>127.0.0.1
    - <span class="nt">--client-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/ca.crt
    - <span class="nt">--cluster-cidr</span><span class="o">=</span>10.244.0.0/16
    - <span class="nt">--cluster-name</span><span class="o">=</span>kubernetes
    - <span class="nt">--cluster-signing-cert-file</span><span class="o">=</span>/etc/kubernetes/pki/ca.crt
    - <span class="nt">--cluster-signing-key-file</span><span class="o">=</span>/etc/kubernetes/pki/ca.key
    - <span class="nt">--controllers</span><span class="o">=</span><span class="k">*</span>,bootstrapsigner,tokencleaner
    - <span class="nt">--kubeconfig</span><span class="o">=</span>/etc/kubernetes/controller-manager.conf
    - <span class="nt">--leader-elect</span><span class="o">=</span><span class="nb">true</span>
    - <span class="nt">--node-cidr-mask-size</span><span class="o">=</span>24
    - <span class="nt">--requestheader-client-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/front-proxy-ca.crt
    - <span class="nt">--root-ca-file</span><span class="o">=</span>/etc/kubernetes/pki/ca.crt
    - <span class="nt">--service-account-private-key-file</span><span class="o">=</span>/etc/kubernetes/pki/sa.key
    - <span class="nt">--service-cluster-ip-range</span><span class="o">=</span>10.96.0.0/12
    - <span class="nt">--use-service-account-credentials</span><span class="o">=</span><span class="nb">true
    </span>image: k8s.gcr.io/kube-controller-manager:v1.18.3
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: <span class="nb">true</span>
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: <span class="nb">true</span>
    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: <span class="nb">true</span>
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: <span class="nb">true</span>
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: <span class="nb">true</span>
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: <span class="nb">true
  </span>hostNetwork: <span class="nb">true
  </span>priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      <span class="nb">type</span>: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      <span class="nb">type</span>: DirectoryOrCreate
    name: flexvolume-dir
  - hostPath:
      path: /etc/kubernetes/pki
      <span class="nb">type</span>: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      <span class="nb">type</span>: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /usr/local/share/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      <span class="nb">type</span>: DirectoryOrCreate
    name: usr-share-ca-certificates
status: <span class="o">{}</span>
</code></pre></div></div>

<p>scheduler</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - <span class="nb">command</span>:
    - kube-scheduler
    - <span class="nt">--authentication-kubeconfig</span><span class="o">=</span>/etc/kubernetes/scheduler.conf
    - <span class="nt">--authorization-kubeconfig</span><span class="o">=</span>/etc/kubernetes/scheduler.conf
    - <span class="nt">--bind-address</span><span class="o">=</span>127.0.0.1
    - <span class="nt">--kubeconfig</span><span class="o">=</span>/etc/kubernetes/scheduler.conf
    - <span class="nt">--leader-elect</span><span class="o">=</span><span class="nb">true
    </span>image: k8s.gcr.io/kube-scheduler:v1.18.3
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-scheduler
    resources:
      requests:
        cpu: 100m
    volumeMounts:
    - mountPath: /etc/kubernetes/scheduler.conf
      name: kubeconfig
      readOnly: <span class="nb">true
  </span>hostNetwork: <span class="nb">true
  </span>priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/kubernetes/scheduler.conf
      <span class="nb">type</span>: FileOrCreate
    name: kubeconfig
status: <span class="o">{}</span>
</code></pre></div></div>

<p>https://github.com/kubernetes-sigs/kubespray)</p>


      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
    
  </body>
</html>
